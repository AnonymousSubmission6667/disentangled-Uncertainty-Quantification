{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-benchmark using fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# to remplace with pip install abench and uqmodels\n",
    "path = '../'\n",
    "sys.path.insert(1, path)\n",
    "sys.path.insert(1, path+'src')\n",
    "import abench as abench\n",
    "import uqmodels as uqmodels\n",
    "import abench.store as A_store\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalisation modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/Benchmark_synthetic_injection_inference already exists\n",
      "% train for each sub sample for each set\n",
      "cv_0  len 60000 %train/test/drop: [10.   3.3] [25.   8.3] [40.  13.3]\n",
      "cv_1  len 60000 %train/test/drop: [10.   3.3] [25.   8.3] [40.  13.3]\n",
      "cv_0_bis1  len 60000 %train/test/drop: [10.   3.3] [25.   8.3] [40.  13.3]\n",
      "cv_1_bis1  len 60000 %train/test/drop: [10.   3.3] [25.   8.3] [40.  13.3]\n"
     ]
    }
   ],
   "source": [
    "#Data_processor for preprocessed data stored in a dict\n",
    "import abench.store as A_store\n",
    "from abench.benchmark import dataset_generator_from_array,splitter,TimeSeriesSplit,analyse_data_generator\n",
    "from src.Benchmark_UQ import Encapsulated_model_UQ,TimeSeries_from_dict\n",
    "from src.attack_function import ctx_seq_attack_UC_AL, ctx_seq_attack, test_attack\n",
    "from uqmodels.utils import compute_born\n",
    "\n",
    "# Type_experiments : Training_inj or Inference_inj\n",
    "Type_exp = \"Inference_inj\" # \"Inference_inj\"\n",
    "\n",
    "# Load Synthetic data\n",
    "Folder_data = path + 'data/synthetic_data/'\n",
    "Name_data = 'synthetic_data_multivariate.p'\n",
    "Synthetic_dataset = TimeSeries_from_dict(Folder_data+Name_data)\n",
    "Synthetic_dataset.process()\n",
    "X,y,context,train,test, X_split = Synthetic_dataset.get_data()\n",
    "y = y[:,1:2] # Reduce to an Univariate forecast task\n",
    "X_shape,y_shape = X.shape[-1],y.shape[-1]\n",
    "\n",
    "# Preliminairies setup for data_generator\n",
    "X_train, X_test, y_train, y_test, context_train,context_test = Synthetic_dataset.split_train_test()\n",
    "context = np.concatenate([context,(context[:,0]<20)[:,None]],axis=1)\n",
    "sk_split = TimeSeriesSplit(n_splits=2,max_train_size=int(len(X)/2),test_size=int(len(X)/4))\n",
    "objective = None\n",
    "dataset_generator = dataset_generator_from_array(X,y,context,objective,\n",
    "                                                 sk_split=sk_split,\n",
    "                                                 remove_from_train=None,\n",
    "                                                 repetition=2,\n",
    "                                                 cv_list_name=['cv_0','cv_1'])\n",
    "\n",
    "# Build and store data_generator from data\n",
    "if(Type_exp==\"Training_inj\"):\n",
    "    storing = path+'results/Benchmark_synthetic_learning_injection'\n",
    "    if not os.path.exists(storing):\n",
    "        dataset_generator = dataset_generator_from_array(X,y,context,objective,\n",
    "                                                         sk_split=sk_split,\n",
    "                                                         remove_from_train=None,\n",
    "                                                         repetition=2,\n",
    "                                                         cv_list_name=['cv_0','cv_1'])\n",
    "\n",
    "        remove_from_train_seq_ctx1_bis = ctx_seq_attack(y,context,1,0.95)\n",
    "        dataset_generator_deg1_bis = dataset_generator_from_array(X,y,context,objective,\n",
    "                                                              sk_split=sk_split,\n",
    "                                                              repetition=2,\n",
    "                                                              remove_from_train=remove_from_train_seq_ctx1_bis,\n",
    "                                                              cv_list_name=['cv_0_deg1_seq97','cv_1_deg1_seq97'])\n",
    "\n",
    "\n",
    "        remove_from_train_seq_ctx1_bis = ctx_seq_attack(y,context,1,1)\n",
    "        dataset_generator_deg2_bis = dataset_generator_from_array(X,y,context,objective,\n",
    "                                                              sk_split=sk_split,\n",
    "                                                              repetition=2,\n",
    "                                                              remove_from_train=remove_from_train_seq_ctx1_bis,\n",
    "                                                              cv_list_name=['cv_0_deg1_seq100','cv_1_deg1_seq100'])\n",
    "\n",
    "\n",
    "        dataset_generator = dataset_generator + dataset_generator_deg1_bis + dataset_generator_deg2_bis\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        A_store.store_data_generator(storing,dataset_generator)\n",
    "    else:\n",
    "        dataset_generator = A_store.get_data_generator(storing)\n",
    "        print(storing+' already exists')\n",
    "    \n",
    "if(Type_exp==\"Inference_inj\"):\n",
    "    from src.attack_function import injection_on_data_generator\n",
    "    storing = path+'results/Benchmark_synthetic_injection_inference'\n",
    "    if not os.path.exists(storing):\n",
    "        dataset_generator = dataset_generator_from_array(X,y,context,objective,\n",
    "                                                     sk_split=sk_split,\n",
    "                                                     remove_from_train=None,\n",
    "                                                     repetition=2,\n",
    "                                                     cv_list_name=['cv_0','cv_1'])\n",
    "        list_f = [10,11,0,3,6] # Strongest contribution features using Shape\n",
    "        type_f = ['Num','Num','Num','Num','Num']\n",
    "        type_attack = [('small',2),('small',5),('strong',2),('strong',5)]\n",
    "        force = 0\n",
    "        dataset_generator_with_attack = injection_on_data_generator(dataset_generator,type_attack,\n",
    "                                                                    type_f,list_f,force)\n",
    "\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        store_data_generator(storing,data_generator)\n",
    "    else:\n",
    "        print(storing+' already exists')\n",
    "        dataset_generator = A_store.get_data_generator(storing)\n",
    "\n",
    "analyse_data_generator(dataset_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uqmodels.common.basic_NN import build_MSE_loss,build_BNN_loss,mlp,default_callbacks\n",
    "\n",
    "# MLP - BNN\n",
    "type_var = None\n",
    "callbacks = default_callbacks(min_delta=0.005,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0,)\n",
    "step=1000\n",
    "model_param={'dim_in':X.shape[-1],'dim_out':y.shape[-1], 'layers_size':[200,300,200],\n",
    "             'regularizer_W':(0.00003,0.00003),'name':'','dp':0.02,'type_var':type_var,\n",
    "             'logvar_min':np.log(0.00001)}\n",
    "            #(0.0001,0.0001)\n",
    "training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0001],'sample_w':None,\n",
    "    'list_loss':[build_MSE_loss],'metrics':None,\n",
    "    'param_loss':[1],'callbacks':callbacks}\n",
    "\n",
    "MLP_parameters = {'rescale':True,\n",
    "                      'model_initializer':mlp,\n",
    "                      'model_parameters':model_param,\n",
    "                      'training_parameters':training_param,\n",
    "                      'type_var':type_var}\n",
    "\n",
    "# RF_dUQ\n",
    "estimator = RandomForestRegressor(ccp_alpha=1e-05, max_depth=20, max_features=0.5,\n",
    "                                  max_samples=0.99, min_impurity_decrease=1e-05,\n",
    "                                  min_samples_leaf=2, min_samples_split=4, n_estimators=50,\n",
    "                                  random_state=None)\n",
    "\n",
    "RF_dUQ_parameters = {'estimator':estimator,\n",
    "                     'pretuned':False,\n",
    "                     'mode':'sigma',\n",
    "                     'use_biais':True,\n",
    "                     'rescale':True}\n",
    "\n",
    "# PNN_MCDP \n",
    "type_var = 'MC_Dropout'\n",
    "callbacks = default_callbacks(min_delta=0.005,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0,)\n",
    "step=1000\n",
    "\n",
    "model_param={'dim_in':X.shape[-1],'dim_out':y.shape[-1], 'layers_size':[200,300,200],\n",
    "             'regularizer_W':(0.0003,0.0003),'name':'','dp':0.20,'type_var':type_var,'n_ech':8,\n",
    "             'logvar_min':np.log(0.00001)}\n",
    "            #(0.0001,0.0001)\n",
    "training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0005],\n",
    "                  'sample_w':None,\n",
    "    'list_loss':[build_BNN_loss],'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "    'param_loss':[1.05],'callbacks':callbacks}\n",
    "\n",
    "PNN_MCDP_parameters = {'rescale':True,\n",
    "                      'model_initializer':mlp,\n",
    "                      'model_parameters':model_param,\n",
    "                      'training_parameters':training_param,\n",
    "                      'type_var':type_var}\n",
    "\n",
    "#EDL \n",
    "type_var = 'EDL'\n",
    "from uqmodels.common.basic_NN import build_EDL_loss,build_BNN_loss,mlp\n",
    "callbacks = default_callbacks(min_delta=0.0005,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0)\n",
    "\n",
    "model_param={'dim_in':X.shape[-1],'dim_out':y.shape[-1], 'layers_size':[200,300,200],\n",
    "             'regularizer_W':(0.0001,0.0001),'name':'','dp':0.02,'type_var':type_var,'logvar_min':np.log(0.00001)}\n",
    "         #'regularizer_W':(0.0003,0.0003)\n",
    "training_param = {'epochs':[step,step,step],'b_s':[200,50,100],\n",
    "                  'l_r':[0.001,0.0005,0.0001],'sample_w':None,'list_loss':[build_EDL_loss],\n",
    "                  'metrics':[build_MSE_loss(4,True),build_BNN_loss(0.9,True,type_var)],\n",
    "                  'callbacks':callbacks,'param_loss':[13e-2]}\n",
    "\n",
    "EDL_parameters = {'rescale':False,\n",
    "                  'model_initializer':mlp,\n",
    "                  'model_parameters':model_param,\n",
    "                  'training_parameters':training_param,\n",
    "                  'type_var':type_var}\n",
    "\n",
    "# MLP - BNN\n",
    "type_var = \"Deep_ensemble\"\n",
    "callbacks = default_callbacks(min_delta=0.0005,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0,)\n",
    "step=1000\n",
    "\n",
    "model_param={'dim_in':X.shape[-1],'dim_out':y.shape[-1], 'layers_size':[200,300,200],\n",
    "             'train_ratio':0.95,'n_ech':5,'k_fold':None,\n",
    "             'regularizer_W':(0.001,0.001),'name':'','dp':0.02,'type_var':type_var,\n",
    "             'logvar_min':np.log(0.00001)}\n",
    "training_param = {'epochs':[step,step],'b_s':[128,64],'l_r':[0.001,0.0005],\n",
    "                  'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                  'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                  'param_loss':[1],'callbacks':callbacks}\n",
    "\n",
    "PNN_DE_parameters = {'model_initializer':mlp,\n",
    "                     'model_parameters':model_param,\n",
    "                     'training_parameters':training_param,\n",
    "                     'type_var':type_var}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalisation tache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from uqmodels.common.random_forest_UQ import PredictorRF_UQ_distangle\n",
    "from uqmodels.common.neural_network_UQ import NN_var\n",
    "random = np.random.randint(10000000)\n",
    "\n",
    "# Transmision des modèles / Initialisateurs de modèles\n",
    "dict_Predictor={}\n",
    "\n",
    "dict_Predictor['RF_dUQ'] = {'subpart':PredictorRF_UQ_distangle,'parameters':RF_dUQ_parameters}           \n",
    "dict_Predictor['MLP'] = {'subpart':NN_var,'parameters':MLP_parameters}    \n",
    "dict_Predictor['PNN_DE'] = {'subpart':NN_var,'parameters':PNN_DE_parameters}    \n",
    "dict_Predictor['PNN_MCDP'] = {'subpart':NN_var,'parameters':PNN_MCDP_parameters}    \n",
    "dict_Predictor['EDL'] = {'subpart':NN_var,'parameters':EDL_parameters}\n",
    "\n",
    "exp_design=[]\n",
    "# Spécification du plan d'expérience\n",
    "exp_design.append([{'name':'RF_dUQ_bis','model':'RF_dUQ'},\n",
    "                   {'name':'MLP_bis','model':'MLP'}\n",
    "                   {'name':'PNN_DE_bis','model':'PNN_DE'}\n",
    "                   {'name':'PNN_MCDP_bis','model':'PNN_MCDP'}\n",
    "                   {'name':'EDL_bis','model':'EDL'}])\n",
    "\n",
    "# Model wrapper :\n",
    "from src.Benchmark_UQ import Encapsulated_model_UQ\n",
    "# Configuration transmis à abench coté modèle\n",
    "dict_exp={'encapsulated_model': Encapsulated_model_UQ,\n",
    "          'tuning_scheme' : {'model':(X[train],y[train])},\n",
    "          'model' : dict_Predictor,\n",
    "          'exp_design':exp_design}\n",
    "\n",
    "#print(list_cv_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_experiments : 0\n",
      "PNN_MCDP_bis\n",
      "load existant data_set\n",
      "start cv_0\n",
      "start_fit\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "1875/1875 [==============================] - 7s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "cv_0 len_train 8000\n",
      "[(['Rmse_all'], [0.394890228183241, 0.4395592284835785]), (['Cov_ALL'], [0.97975, 0.959]), (['Aw_E'], [0.8092865002813542, 0.8151782910371864]), (['Aw_A'], [1.607894199142769, 1.6012442933448214])]\n",
      "start cv_1\n",
      "start_fit\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "cv_1 len_train 8000\n",
      "[(['Rmse_all'], [0.4076735671413856, 0.44721640543337443]), (['Cov_ALL'], [0.98175, 0.96275]), (['Aw_E'], [0.8040160226241312, 0.8587424080471446]), (['Aw_A'], [1.642042807513049, 1.6994090063935923])]\n",
      "start cv_0_bis1\n",
      "start_fit\n",
      "1875/1875 [==============================] - 7s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 7s 3ms/step\n",
      "cv_0_bis1 len_train 8000\n",
      "[(['Rmse_all'], [0.39921690245964503, 0.44487470175820504]), (['Cov_ALL'], [0.98025, 0.96025]), (['Aw_E'], [0.79989643340918, 0.7957533210364065]), (['Aw_A'], [1.6387460773583926, 1.6262914857261095])]\n",
      "start cv_1_bis1\n",
      "start_fit\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "cv_1_bis1 len_train 8000\n",
      "[(['Rmse_all'], [0.39686509021082306, 0.45004103756113095]), (['Cov_ALL'], [0.98175, 0.96325]), (['Aw_E'], [0.8075174408199236, 0.8586788503900951]), (['Aw_A'], [1.6223807205936387, 1.6790236480622642])]\n",
      "cv_0 len_train 8000\n",
      "cv_1 len_train 8000\n",
      "cv_0_bis1 len_train 8000\n",
      "cv_1_bis1 len_train 8000\n"
     ]
    }
   ],
   "source": [
    "#Load Task encapsulator model\n",
    "\n",
    "# Metrics definition to encapsulate in Generic_metric\n",
    "\n",
    "    \n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness\n",
    "from abench.benchmark import Generic_metric\n",
    "\n",
    "list_ctx_constraint= None\n",
    "if(True):\n",
    "    list_ctx_constraint= [(-2,None,0.5)]\n",
    "list_metrics=[Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "              Generic_metric(average_coverage,\"Cov_ALL\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var=\"all\"),\n",
    "              Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var=\"epistemic\"),\n",
    "              Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var=\"aleatoric\")]\n",
    "\n",
    "obj_param = {'alpha':0.05}\n",
    "tuning_kwarg = {}\n",
    "\n",
    "#Start from empty dict\n",
    "\n",
    "from abench.benchmark import benchmark\n",
    "cv_list = A_store.get_cv_list(storing)\n",
    "storing = benchmark(storing,None,dict_exp,obj_param,\n",
    "                    list_metrics,tuning_kwarg=tuning_kwarg,verbose=0,cv_list=cv_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_0 len_train 8000\n",
      "cv_1 len_train 8000\n",
      "cv_0_bis1 len_train 8000\n",
      "cv_1_bis1 len_train 8000\n",
      "MLP  |time_fit : 237.57 time_pred : 1.38\n",
      "Rmse_all Train 0.381 ± 0.001 | TEST 0.428 ± 0.002\n",
      "Cov_all Train 1.0 ± 0.0 | TEST 1.0 ± 0.0\n",
      "NLL Train 2.247 ± 0.005 | TEST 2.248 ± 0.005\n",
      "sharpness Train 14.979 ± 0.078 | TEST 14.979 ± 0.078\n",
      "\n",
      "RF_dUQ  |time_fit : 10.54 time_pred : 15.18\n",
      "Rmse_all Train 0.241 ± 0.003 | TEST 0.433 ± 0.002\n",
      "Cov_all Train 1.0 ± 0.0 | TEST 0.967 ± 0.002\n",
      "NLL Train 0.068 ± 0.009 | TEST 0.438 ± 0.009\n",
      "sharpness Train 1.547 ± 0.015 | TEST 1.79 ± 0.013\n",
      "\n",
      "PNN_MCDP  |time_fit : 641.03 time_pred : 16.34\n",
      "Rmse_all Train 0.395 ± 0.002 | TEST 0.442 ± 0.002\n",
      "Cov_all Train 0.982 ± 0.001 | TEST 0.963 ± 0.001\n",
      "NLL Train 0.347 ± 0.003 | TEST 0.466 ± 0.012\n",
      "sharpness Train 1.821 ± 0.008 | TEST 1.858 ± 0.05\n",
      "\n",
      "PNN_DE  |time_fit : 2968.25 time_pred : 6.87\n",
      "Rmse_all Train 0.396 ± 0.002 | TEST 0.428 ± 0.004\n",
      "Cov_all Train 0.968 ± 0.001 | TEST 0.95 ± 0.001\n",
      "NLL Train 0.298 ± 0.002 | TEST 0.401 ± 0.016\n",
      "sharpness Train 1.547 ± 0.005 | TEST 1.565 ± 0.029\n",
      "\n",
      "EDL  |time_fit : 609.75 time_pred : 11.51\n",
      "Rmse_all Train 0.415 ± 0.001 | TEST 0.441 ± 0.002\n",
      "Cov_all Train 0.974 ± 0.0 | TEST 0.965 ± 0.002\n",
      "NLL Train 0.366 ± 0.006 | TEST 0.442 ± 0.011\n",
      "sharpness Train 1.774 ± 0.014 | TEST 1.8 ± 0.036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from abench.benchmark import evaluate, Generic_metric\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "\n",
    "storing = path+'results/Benchmark_synthetic_injection_learning'\n",
    "cv_list = ['cv_0','cv_1','cv_0_bis1','cv_1_bis1']\n",
    "list_name = ['MLP','RF_dUQ','PNN_MCDP','PNN_DE','EDL']\n",
    "list_ctx_constraint= None\n",
    "list_metrics = [Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "                Generic_metric(average_coverage,\"Cov_all\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "                Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var='all'),\n",
    "                Generic_metric(sharpness,\"sharpness\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var='all'),]\n",
    "dict_perf = evaluate(storing, list_name, list_metrics,verbose=1,cv_list=cv_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
