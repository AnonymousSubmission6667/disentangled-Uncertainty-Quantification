{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-benchmark using fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# to remplace with pip install abench and uqmodels\n",
    "path = '../'\n",
    "sys.path.insert(1, path)\n",
    "sys.path.insert(1, path+'src')\n",
    "\n",
    "import abench as abench\n",
    "import uqmodels as uqmodels\n",
    "import abench.store as A_store\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data_folder = path+'data/Public_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalisation modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 12:14:39.427254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 9)\n",
      "results/Benchmark_public/Benchmark_public_dataset_kin8nm already exists\n"
     ]
    }
   ],
   "source": [
    "#Data_processor for preprocessed data stored in a dict\n",
    "from abench.benchmark import dataset_generator_from_array,splitter,TimeSeriesSplit,KFold,splitter\n",
    "from abench.store import store_data_generator\n",
    "from src.Benchmark_UQ import Encapsulated_model_UQ,TimeSeries_from_dict\n",
    "from src.attack_function import ctx_seq_attack_UC_AL, ctx_seq_attack, test_attack\n",
    "\n",
    "#Choice of public dataset\n",
    "num_dataset = 1\n",
    "data_folder = path+'data/Public_dataset/'\n",
    "n_repet = 1\n",
    "\n",
    "if(num_dataset==1):\n",
    "    storing =path+'results/Benchmark_public/Benchmark_public_dataset_kin8nm'\n",
    "    dataset = pd.read_csv(data_folder+\"dataset_2175_kin8nm.csv\")\n",
    "    print(dataset.shape)\n",
    "    dataset.head()\n",
    "    X = dataset[['theta1','theta2','theta3','theta4','theta5','theta6','theta7','theta8']].values\n",
    "    y = dataset['y'].values.reshape(-1,1)\n",
    "    X_shape,y_shape=X.shape[-1],y.shape[-1]\n",
    "    split=KFold(5)\n",
    "    name_split = ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "    dataset_generator = dataset_generator_from_array(X,y,None,None,\n",
    "                                                     sk_split=split,\n",
    "                                                     remove_from_train=None,\n",
    "                                                     attack_name=\"\",\n",
    "                                                     cv_list_name=name_split)\n",
    "    if not os.path.exists(storing):\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        store_data_generator(storing,data_generator)\n",
    "    else:\n",
    "        print(storing+' already exists')\n",
    "    \n",
    "elif(num_dataset==2):\n",
    "    storing =path+'results/Benchmark_public/Benchmark_public_dataset_Folds5x2_pp'\n",
    "    dataset = pd.read_csv(data_folder+\"Folds5x2_pp.csv\")\n",
    "    X = dataset[['AT','V','AP','RH']].values\n",
    "    y = dataset['PE'].values.reshape(-1,1)\n",
    "    X_shape,y_shape=X.shape[-1],y.shape[-1]\n",
    "    split=KFold(5)\n",
    "    name_split = ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "    if not os.path.exists(storing):\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        store_data_generator(storing,data_generator)\n",
    "    else:\n",
    "        print(storing+' already exists')\n",
    "\n",
    "elif(num_dataset==3):\n",
    "    storing =path+'results/Benchmark_public/Benchmark_public_dataset_CASP_protein'\n",
    "    dataset = pd.read_csv(data_folder+\"CASP_protein.csv\")\n",
    "    X = dataset.iloc[:,1:].values\n",
    "    y = dataset.iloc[:,:1].values.reshape(-1,1)\n",
    "    X_shape,y_shape=X.shape[-1],y.shape[-1]\n",
    "    name_split = ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "    split=KFold(5)\n",
    "    if not os.path.exists(storing):\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        store_data_generator(storing,data_generator)\n",
    "    else:\n",
    "        print(storing+' already exists')\n",
    "    \n",
    "elif(num_dataset==4):\n",
    "    print('Warning : big dataset may take some minutes')\n",
    "    storing =path+'results/Benchmark_public/Benchmark_public_dataset_year_prediction'\n",
    "    X_shape,y_shape=90,-1\n",
    "    name_split = ['cv_1']\n",
    "    if not os.path.exists(storing):\n",
    "        print('Warning : big dataset, may take some minutes')\n",
    "        dataset = pd.read_csv(data_folder+\"year_prediction.csv\")\n",
    "        X=dataset[0][0]\n",
    "        y=dataset[0][1]\n",
    "        split = sk_split=splitter(np.arange(515345)>463715)   #train: first 463,715 examples test: last 51,630 examples\n",
    "        dataset_generator = dataset_generator_from_array(X,y,None,None,\n",
    "                                             sk_split=split,\n",
    "                                             repetition=n_repet,\n",
    "                                             remove_from_train=None,\n",
    "                                             attack_name=\"\",cv_list_name=name_split)\n",
    "        print('Generation of data-generator at '+storing)\n",
    "        store_data_generator(storing,data_generator)\n",
    "    else:\n",
    "        print(storing+' already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from uqmodels.common.predictors import PredictorRF_UQ_distangle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(num_dataset)\n",
    "#Tunning process : \n",
    "if(False):\n",
    "    rf_config = {'n_estimators': [100,200,300],\n",
    "     'min_impurity_decrease': [0.00001,0.0001,0.001, 0.01],\n",
    "     'ccp_alpha': [0.00000,0.00001,0.0001, 0.001],\n",
    "     'max_features': [0.5, 0.7, 0.9, 0.99],\n",
    "     'max_samples': [0.5, 0.7, 0.9, 0.99],\n",
    "     'max_depth': [6, 9, 12, 15, 20],\n",
    "     'min_samples_split': [2,4,6, 8, 10, 15],\n",
    "     'min_samples_leaf': [2,4,6,8,10,15]}\n",
    "    RF = PredictorRF_UQ_distangle()\n",
    "    X_,y_,split_,_,_,_ = dataset_generator[0]\n",
    "    print(len(X_))\n",
    "    train = split_==1\n",
    "    RF_tuning(X_[train], y_[train,0], n_esti=200, folds=3, params=rf_config)\n",
    "    estimator = RF.estimator_mean\n",
    "\n",
    "elif(num_dataset==1):\n",
    "    estimator = RandomForestRegressor(ccp_alpha=1e-05, max_depth=15, max_features=0.5,\n",
    "                      max_samples=0.99, min_impurity_decrease=1e-05,\n",
    "                      min_samples_leaf=2, min_samples_split=6)\n",
    "    \n",
    "elif(num_dataset==2):\n",
    "    estimator = RandomForestRegressor(ccp_alpha=1e-05, max_depth=20, max_features=0.7,\n",
    "                          max_samples=0.99, min_impurity_decrease=0.0001,\n",
    "                          min_samples_leaf=2, min_samples_split=8)\n",
    "    \n",
    "elif(num_dataset==3):\n",
    "    estimator = RandomForestRegressor(ccp_alpha=1e-05, max_depth=20, max_features=0.7,\n",
    "                          max_samples=0.99, min_impurity_decrease=0.0001,\n",
    "                          min_samples_leaf=2, min_samples_split=8)\n",
    "    \n",
    "elif(num_dataset==4):\n",
    "    estimator = RandomForestRegressor(ccp_alpha=0.0001, max_depth=15, max_features=0.7,\n",
    "                      max_samples=0.9, min_impurity_decrease=0.0001,\n",
    "                      min_samples_leaf=10, min_samples_split=8,\n",
    "                      n_estimators=300)\n",
    "\n",
    "RF_dUQ_parameters = {'estimator':estimator,\n",
    "                 'pretuned':False,\n",
    "                 'mode':'sigma',\n",
    "                 'use_biais':True,\n",
    "                 'var_min':0.00001,\n",
    "                 'rescale':True}\n",
    "\n",
    "# MLP - BNN\n",
    "from uqmodels.common.basic_NN import build_MSE_loss,build_BNN_loss,mlp,default_callbacks\n",
    "\n",
    "callbacks = default_callbacks(min_delta=0.001,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0,)\n",
    "step = 500\n",
    "type_var = 'MC_Dropout'\n",
    "# PNN_MCDP\n",
    "if(num_dataset==1):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'regularizer_W':(0.0002,0.0002),'name':'','dp':0.10,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00001)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0001],\n",
    "                  'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                  'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                  'param_loss':[1.15],'callbacks':callbacks}\n",
    "\n",
    "if(num_dataset==2):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'regularizer_W':(0.0002,0.0002),'name':'','dp':0.10,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00001)}\n",
    "        \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0001],\n",
    "                  'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                  'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                  'param_loss':[1.15],'callbacks':callbacks}\n",
    "                      \n",
    "if(num_dataset==3):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'regularizer_W':(0.00008,0.00008),'name':'','dp':0.13,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00001)}\n",
    "        \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0001],\n",
    "                  'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                  'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                  'param_loss':[1.15],'callbacks':callbacks}\n",
    "    \n",
    "if(num_dataset==4):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,300,200],\n",
    "                'regularizer_W':(0.0005,0.0005),'name':'','dp':0.22,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00001)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[256,64,126],'l_r':[0.001,0.0005,0.0001],\n",
    "                  'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                  'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                  'param_loss':[1.1],'callbacks':callbacks}\n",
    "\n",
    "\n",
    "PNN_MCDP_parameters = {'rescale':True,\n",
    "                     'model_initializer':mlp,\n",
    "                     'model_parameters':model_param,\n",
    "                     'training_parameters':training_param,\n",
    "                     'type_var':type_var}\n",
    "\n",
    "# EDL \n",
    "from uqmodels.common.basic_NN import build_EDL_loss,build_BNN_loss,mlp\n",
    "callbacks = default_callbacks(min_delta=0.005,earlystop_patience=60,reducelr_patience=30,reducelr_factor=0.4,reduce_lr_min_lr=5e-06,verbose=0)\n",
    "step = 500\n",
    "type_var = 'EDL'\n",
    "if(num_dataset==1):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'regularizer_W':(0.0008,0.0008),'name':'','dp':0.03,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00005)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],\n",
    "                      'l_r':[0.001,0.0005,0.0001],'sample_w':None,'list_loss':[build_EDL_loss],\n",
    "                      'metrics':[build_MSE_loss(4,True),build_BNN_loss(0.9,True,type_var)],\n",
    "                      'callbacks':callbacks,'param_loss':[2e-1]}\n",
    "if(num_dataset==2):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'regularizer_W':(0.00005,0.00005),'name':'','dp':0.02,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00005)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],\n",
    "                      'l_r':[0.001,0.0005,0.0001],'sample_w':None,'list_loss':[build_EDL_loss],\n",
    "                      'metrics':[build_MSE_loss(4,True),build_BNN_loss(0.9,True,type_var)],\n",
    "                      'callbacks':callbacks,'param_loss':[10e-3]}\n",
    "    \n",
    "if(num_dataset==3):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "             'regularizer_W':(0.00005,0.00005),'name':'','dp':0.02,'type_var':type_var,\n",
    "             'logvar_min':np.log(0.00005)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],\n",
    "                      'l_r':[0.001,0.0005,0.0001],'sample_w':None,'list_loss':[build_EDL_loss],\n",
    "                      'metrics':[build_MSE_loss(4,True),build_BNN_loss(0.9,True,type_var)],\n",
    "                      'callbacks':callbacks,'param_loss':[5e-4]}\n",
    "    \n",
    "if(num_dataset==4):    \n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,300,200],\n",
    "             'regularizer_W':(0.0004,0.0004),'name':'','dp':0.02,'type_var':type_var,\n",
    "             'logvar_min':np.log(0.00005)}\n",
    "    \n",
    "    training_param = {'epochs':[step,step,step],'b_s':[256,64,128],\n",
    "                      'l_r':[0.001,0.0005,0.0001],'sample_w':None,'list_loss':[build_EDL_loss],\n",
    "                      'metrics':[build_MSE_loss(4,True),build_BNN_loss(0.9,True,type_var)],\n",
    "                      'callbacks':callbacks,'param_loss':[1e-5]}\n",
    "    \n",
    "\n",
    "EDL_parameters = {'rescale':True,\n",
    "                  'model_initializer':mlp,\n",
    "                  'model_parameters':model_param.copy(),\n",
    "                  'training_parameters':training_param.copy(),\n",
    "                  'type_var': 'EDL'}\n",
    "\n",
    "#PNN_DE\n",
    "type_var = 'Deep_ensemble'\n",
    "if(num_dataset==1):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "                 'n_ech':6,'k_fold':None,\"snapshot\":False,'data_drop':0.1,'train_ratio':0.95,'ddof':1,\n",
    "                 'regularizer_W':(0.002,0.002),'name':'','dp':0.02,'type_var':type_var,\n",
    "                 'logvar_min':np.log(0.00001)}\n",
    "\n",
    "    training_param = {'epochs':[step,step],'b_s':[200,100],'l_r':[0.001,0.0005],'sample_w':None,\n",
    "        'list_loss':[build_BNN_loss],'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "        'param_loss':[0.85],'callbacks':callbacks}\n",
    "    \n",
    "if(num_dataset==2):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "             'n_ech':4,'k_fold':None,\"snapshot\":False,'data_drop':0,'train_ratio':0.95,'ddof':1,\n",
    "             'regularizer_W':(0.00003,0.00003),'name':'','dp':0.02,'type_var':type_var,\n",
    "             'logvar_min':np.log(0.00001)}\n",
    "\n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0005],'sample_w':None,\n",
    "        'list_loss':[build_BNN_loss],'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "        'param_loss':[1.5],'callbacks':callbacks}\n",
    "    \n",
    "if(num_dataset==3):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,200],\n",
    "         'n_ech':4,'k_fold':None,\"snapshot\":False,'data_drop':0,'train_ratio':0.95,'ddof':1,\n",
    "         'regularizer_W':(0.00003,0.00003),'name':'','dp':0.02,'type_var':type_var,\n",
    "         'logvar_min':np.log(0.00001)}\n",
    "\n",
    "    training_param = {'epochs':[step,step,step],'b_s':[128,32,64],'l_r':[0.001,0.0005,0.0005],'sample_w':None,\n",
    "        'list_loss':[build_BNN_loss],'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "        'param_loss':[1.5],'callbacks':callbacks}\n",
    "    \n",
    "if(num_dataset==4):\n",
    "    model_param={'dim_in':X_shape,'dim_out':y_shape, 'layers_size':[200,300,300,200],\n",
    "         'n_ech':4,'k_fold':None,\"snapshot\":False,'data_drop':0,'train_ratio':0.95,'ddof':1,\n",
    "         'regularizer_W':(0.0003,0.0003),'name':'','dp':0.02,'type_var':type_var,\n",
    "         'logvar_min':np.log(0.00001)}\n",
    "\n",
    "    training_param = {'epochs':[step,step,step],'b_s':[256,64,128],'l_r':[0.001,0.0005,0.0005],\n",
    "                      'sample_w':None,'list_loss':[build_BNN_loss],\n",
    "                      'metrics':[build_MSE_loss(2,True),build_BNN_loss(0.9,True)],\n",
    "                      'param_loss':[1.5],'callbacks':callbacks}\n",
    "\n",
    "\n",
    "PNN_DE_parameters = {'rescale':True,\n",
    "                              'model_initializer':mlp,\n",
    "                              'model_parameters':model_param.copy(),\n",
    "                              'training_parameters':training_param.copy(),\n",
    "                              'type_var':type_var}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalisation tache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from uqmodels.common.predictors import PredictorRF_UQ_distangle\n",
    "from uqmodels.common.neural_network_UQ import NN_var\n",
    "random = np.random.randint(10000000)\n",
    "# Models initializer and parameters stored.\n",
    "dict_Predictor={}\n",
    "\n",
    "dict_Predictor['RF_dUQ'] = {'subpart':PredictorRF_UQ_distangle,'parameters':RF_dUQ_parameters}\n",
    "dict_Predictor['PNN_MCDP'] = {'subpart':NN_var,'parameters':PNN_MCDP_parameters}\n",
    "dict_Predictor['PNN_DE'] = {'subpart':NN_var,'parameters':PNN_DE_parameters}      \n",
    "dict_Predictor['EDL'] = {'subpart':NN_var,'parameters':EDL_parameters}\n",
    "\n",
    "exp_design=[]\n",
    "# Experiment plan specification\n",
    "exp_design.append([{'name':'PNN_MCDP_test','model':'PNN_MCDP'},\n",
    "                   {'name':'PNN_DE_test','model':'PNN_DE'},\n",
    "                   {'name':'EDL_test','model':'EDL'}])\n",
    "\n",
    "# Model wrapper :\n",
    "from src.Benchmark_UQ import Encapsulated_model_UQ\n",
    "# Wrapper configuration provided to abench (benchmark tool)\n",
    "dict_exp={'encapsulated_model': Encapsulated_model_UQ,\n",
    "          'tuning_scheme' : {'model':None},\n",
    "          'model' : dict_Predictor,\n",
    "          'exp_design':exp_design}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/Benchmark_public/Benchmark_public_dataset_kin8nm ['cv_1']\n",
      "n_experiments : 0\n",
      "PNN_MCDP_test\n",
      "load existant data_set\n",
      "start cv_1\n",
      "start_fit\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "cv_1 len_train 6553\n",
      "[(['Rmse_all'], [0.037960100870044214, 0.06898083185931006]), (['NLL'], [-1.8564080708094999, -1.1753754934756029]), (['Cov_ALL'], [0.9851976194109568, 0.849908480780964]), (['Aw_E'], [0.12353160675497799, 0.12654064114351518]), (['Aw_A'], [0.16266245625043438, 0.16310971909415745])]\n",
      "cv_1 len_train 6553\n",
      "PNN_DE_test\n",
      "start cv_1\n",
      "start_fit\n",
      "0.8544178238974516 6\n"
     ]
    }
   ],
   "source": [
    "# Metrics definition to encapsulate in Generic_metric\n",
    "cv_list=['cv_1']\n",
    "print(storing,cv_list)\n",
    "\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "from abench.benchmark import Generic_metric\n",
    "\n",
    "list_metrics=[Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=None,reduce=True),\n",
    "              Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "              Generic_metric(average_coverage,\"Cov_ALL\", mask=None,list_ctx_constraint=None,reduce=True,type_var=\"all\"),\n",
    "              Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=None,reduce=True,type_var=\"epistemic\"),\n",
    "              Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=None,reduce=True,type_var=\"aleatoric\")]\n",
    "\n",
    "obj_param = {'alpha':0.05}\n",
    "tuning_kwarg = {}\n",
    "\n",
    "#Start from empty dict\n",
    "from abench.benchmark import benchmark\n",
    "benchmark(storing,None,dict_exp,obj_param,list_metrics,tuning_kwarg=tuning_kwarg,verbose=0,cv_list=cv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance results on the 4 publics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_1 len_train 6553\n",
      "cv_2 len_train 6553\n",
      "cv_3 len_train 6554\n",
      "cv_4 len_train 6554\n",
      "cv_5 len_train 6554\n",
      "RF_dUQ  |time_fit : 5.49 time_pred : 12.31\n",
      "Rmse_all Train 0.072 Â± 0.001 | TEST 0.143 Â± 0.001\n",
      "NLL Train -0.941 Â± 0.008 | TEST -0.535 Â± 0.004\n",
      "Cov_all Train 1.0 Â± 0.0 | TEST 0.993 Â± 0.001\n",
      "Aw_A Train 0.307 Â± 0.004 | TEST 0.312 Â± 0.003\n",
      "Aw_E Train 0.492 Â± 0.003 | TEST 0.637 Â± 0.003\n",
      "\n",
      "PNN_MCDP  |time_fit : 202.37 time_pred : 7.51\n",
      "Rmse_all Train 0.049 Â± 0.0 | TEST 0.069 Â± 0.001\n",
      "NLL Train -1.528 Â± 0.007 | TEST -1.293 Â± 0.016\n",
      "Cov_all Train 0.996 Â± 0.0 | TEST 0.963 Â± 0.006\n",
      "Aw_A Train 0.251 Â± 0.002 | TEST 0.251 Â± 0.002\n",
      "Aw_E Train 0.15 Â± 0.001 | TEST 0.151 Â± 0.002\n",
      "\n",
      "PNN_DE  |time_fit : 1001.02 time_pred : 5.26\n",
      "Rmse_all Train 0.057 Â± 0.0 | TEST 0.067 Â± 0.001\n",
      "NLL Train -1.452 Â± 0.004 | TEST -1.33 Â± 0.013\n",
      "Cov_all Train 0.992 Â± 0.001 | TEST 0.976 Â± 0.004\n",
      "Aw_A Train 0.284 Â± 0.002 | TEST 0.284 Â± 0.002\n",
      "Aw_E Train 0.069 Â± 0.002 | TEST 0.076 Â± 0.002\n",
      "\n",
      "EDL  |time_fit : 218.94 time_pred : 0.96\n",
      "Rmse_all Train 0.048 Â± 0.001 | TEST 0.068 Â± 0.001\n",
      "NLL Train -1.6 Â± 0.022 | TEST -1.303 Â± 0.015\n",
      "Cov_all Train 0.986 Â± 0.001 | TEST 0.94 Â± 0.009\n",
      "Aw_A Train 0.022 Â± 0.002 | TEST 0.022 Â± 0.002\n",
      "Aw_E Train 0.279 Â± 0.006 | TEST 0.279 Â± 0.006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from abench.benchmark import evaluate, Generic_metric\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "\n",
    "storing =path+'results/Benchmark_public/Benchmark_public_dataset_kin8nm'\n",
    "cv_list =  ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "list_name = ['RF_dUQ','PNN_MCDP','PNN_DE','EDL']\n",
    "list_ctx_constraint=None\n",
    "list_metrics = [Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "                Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(average_coverage,\"Cov_all\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "                Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var='aleatoric'),\n",
    "                Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_var='epistemic')]\n",
    "dict_perf = evaluate(storing, list_name, list_metrics,verbose=1,cv_list=cv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_1 len_train 7654\n",
      "cv_2 len_train 7654\n",
      "cv_3 len_train 7654\n",
      "cv_4 len_train 7655\n",
      "cv_5 len_train 7655\n",
      "RF_dUQ  |time_fit : 1.73 time_pred : 2.16\n",
      "Rmse_all Train 3.276 Â± 0.04 | TEST 3.692 Â± 0.126\n",
      "NLL Train 2.614 Â± 0.006 | TEST 2.693 Â± 0.003\n",
      "Cov_all Train 0.991 Â± 0.001 | TEST 0.98 Â± 0.001\n",
      "Aw_A Train 14.472 Â± 0.1 | TEST 14.522 Â± 0.108\n",
      "Aw_E Train 8.173 Â± 0.069 | TEST 8.735 Â± 0.057\n",
      "\n",
      "PNN_MCDP  |time_fit : 404.99 time_pred : 9.63\n",
      "Rmse_all Train 3.552 Â± 0.041 | TEST 3.754 Â± 0.123\n",
      "NLL Train 2.579 Â± 0.006 | TEST 2.648 Â± 0.006\n",
      "Cov_all Train 0.964 Â± 0.001 | TEST 0.949 Â± 0.002\n",
      "Aw_A Train 13.299 Â± 0.09 | TEST 13.336 Â± 0.09\n",
      "Aw_E Train 4.406 Â± 0.066 | TEST 4.407 Â± 0.073\n",
      "\n",
      "PNN_DE  |time_fit : 1245.34 time_pred : 4.39\n",
      "Rmse_all Train 2.818 Â± 0.075 | TEST 3.449 Â± 0.123\n",
      "NLL Train 2.147 Â± 0.027 | TEST 2.552 Â± 0.018\n",
      "Cov_all Train 0.958 Â± 0.002 | TEST 0.872 Â± 0.006\n",
      "Aw_A Train 8.718 Â± 0.194 | TEST 8.703 Â± 0.229\n",
      "Aw_E Train 2.898 Â± 0.179 | TEST 3.102 Â± 0.188\n",
      "\n",
      "EDL  |time_fit : 385.54 time_pred : 1.23\n",
      "Rmse_all Train 3.151 Â± 0.046 | TEST 3.562 Â± 0.154\n",
      "NLL Train 2.298 Â± 0.029 | TEST 2.549 Â± 0.015\n",
      "Cov_all Train 0.963 Â± 0.001 | TEST 0.915 Â± 0.01\n",
      "Aw_A Train 2.969 Â± 0.383 | TEST 2.968 Â± 0.389\n",
      "Aw_E Train 11.131 Â± 0.208 | TEST 11.132 Â± 0.305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performances for the 4 approaches on Benchmark_public_dataset_Folds5x2_pp with 5-cross val\n",
    "from abench.benchmark import evaluate, Generic_metric\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "\n",
    "storing =path+'results/Benchmark_public/Benchmark_public_dataset_Folds5x2_pp'\n",
    "cv_list =  ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "list_name = ['RF_dUQ','PNN_MCDP','PNN_DE','EDL']\n",
    "list_metrics = [Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(average_coverage,\"Cov_all\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=None,reduce=True,type_var='aleatoric'),\n",
    "                Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=None,reduce=True,type_var='epistemic')]\n",
    "dict_perf = evaluate(storing, list_name, list_metrics,verbose=1,cv_list=cv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_1 len_train 36584\n",
      "cv_2 len_train 36584\n",
      "cv_3 len_train 36584\n",
      "cv_4 len_train 36584\n",
      "cv_5 len_train 36584\n",
      "RF_dUQ  |time_fit : 23.45 time_pred : 26.26\n",
      "Rmse_all Train 2.413 Â± 0.004 | TEST 3.606 Â± 0.043\n",
      "NLL Train 2.287 Â± 0.004 | TEST 2.503 Â± 0.01\n",
      "Cov_all Train 0.997 Â± 0.0 | TEST 0.975 Â± 0.002\n",
      "Aw_A Train 10.9 Â± 0.034 | TEST 10.957 Â± 0.025\n",
      "Aw_E Train 9.174 Â± 0.037 | TEST 10.814 Â± 0.094\n",
      "\n",
      "PNN_MCDP  |time_fit : 1402.87 time_pred : 49.52\n",
      "Rmse_all Train 3.571 Â± 0.129 | TEST 3.778 Â± 0.084\n",
      "NLL Train 2.28 Â± 0.063 | TEST 2.351 Â± 0.046\n",
      "Cov_all Train 0.972 Â± 0.001 | TEST 0.957 Â± 0.004\n",
      "Aw_A Train 5671680845.852 Â± 11343361667.517 | TEST 10951513.707 Â± 21903003.099\n",
      "Aw_E Train 4.151 Â± 0.08 | TEST 4.163 Â± 0.07\n",
      "\n",
      "PNN_DE  |time_fit : 5252.35 time_pred : 21.39\n",
      "Rmse_all Train 2.884 Â± 0.086 | TEST 3.476 Â± 0.081\n",
      "NLL Train 1.766 Â± 0.069 | TEST 2.055 Â± 0.06\n",
      "Cov_all Train 0.973 Â± 0.002 | TEST 0.917 Â± 0.005\n",
      "Aw_A Train 7717845.928 Â± 15342779.291 | TEST 25712505.627 Â± 51245862.772\n",
      "Aw_E Train 3.134 Â± 0.121 | TEST 3.408 Â± 0.14\n",
      "\n",
      "EDL  |time_fit : 2176.44 time_pred : 4.82\n",
      "Rmse_all Train 2.905 Â± 0.042 | TEST 3.567 Â± 0.046\n",
      "NLL Train 3.058 Â± 0.101 | TEST 3.225 Â± 0.097\n",
      "Cov_all Train 0.988 Â± 0.001 | TEST 0.953 Â± 0.005\n",
      "Aw_A Train 42.552 Â± 7.024 | TEST 42.603 Â± 6.91\n",
      "Aw_E Train 25.74 Â± 3.569 | TEST 25.927 Â± 3.602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performances for the 4 approaches on Benchmark_public_dataset_CASP_protein with 5-cross val\n",
    "from abench.benchmark import evaluate, Generic_metric\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "\n",
    "storing =path+'results/Benchmark_public/Benchmark_public_dataset_CASP_protein'\n",
    "cv_list =  ['cv_1','cv_2','cv_3','cv_4','cv_5']\n",
    "list_name = ['RF_dUQ','PNN_MCDP','PNN_DE','EDL']\n",
    "list_metrics = [Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(average_coverage,\"Cov_all\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=None,reduce=True,type_var='aleatoric'),\n",
    "                Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=None,reduce=True,type_var='epistemic')]\n",
    "dict_perf = evaluate(storing, list_name, list_metrics,verbose=1,cv_list=cv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_1 len_train 463716\n",
      "RF_dUQ  |time_fit : 1923.07 time_pred : 625.35\n",
      "Rmse_all Train 7.283 Â± 0.0 | TEST 9.152 Â± 0.0\n",
      "NLL Train 3.278 Â± 0.0 | TEST 3.442 Â± 0.0\n",
      "Cov_all Train 0.992 Â± 0.0 | TEST 0.961 Â± 0.0\n",
      "Aw_A Train 29.358 Â± 0.0 | TEST 29.462 Â± 0.0\n",
      "Aw_E Train 20.186 Â± 0.0 | TEST 21.225 Â± 0.0\n",
      "\n",
      "PNN_MCDP  |time_fit : 24637.9 time_pred : 509.69\n",
      "Rmse_all Train 8.519 Â± 0.0 | TEST 8.753 Â± 0.0\n",
      "NLL Train 3.285 Â± 0.0 | TEST 3.305 Â± 0.0\n",
      "Cov_all Train 0.973 Â± 0.0 | TEST 0.968 Â± 0.0\n",
      "Aw_A Train 32.886 Â± 0.0 | TEST 32.704 Â± 0.0\n",
      "Aw_E Train 5.969 Â± 0.0 | TEST 5.956 Â± 0.0\n",
      "\n",
      "PNN_DE  |time_fit : 33615.0 time_pred : 222.65\n",
      "Rmse_all Train 6.917 Â± 0.0 | TEST 8.714 Â± 0.0\n",
      "NLL Train 2.962 Â± 0.0 | TEST 3.222 Â± 0.0\n",
      "Cov_all Train 0.967 Â± 0.0 | TEST 0.907 Â± 0.0\n",
      "Aw_A Train 20.992 Â± 0.0 | TEST 20.983 Â± 0.0\n",
      "Aw_E Train 8.238 Â± 0.0 | TEST 9.268 Â± 0.0\n",
      "\n",
      "EDL  |time_fit : 23427.62 time_pred : 63.44\n",
      "Rmse_all Train 8.687 Â± 0.0 | TEST 8.903 Â± 0.0\n",
      "NLL Train 3.283 Â± 0.0 | TEST 3.301 Â± 0.0\n",
      "Cov_all Train 0.959 Â± 0.0 | TEST 0.955 Â± 0.0\n",
      "Aw_A Train 2.41 Â± 0.0 | TEST 2.401 Â± 0.0\n",
      "Aw_E Train 33.155 Â± 0.0 | TEST 32.88 Â± 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performances for the 4 approaches on Benchmark_public_dataset_year_prediction without cross-val\n",
    "from abench.benchmark import evaluate, Generic_metric\n",
    "from src.Benchmark_UQ import rmse,average_coverage,sharpness,Gaussian_NLL\n",
    "\n",
    "storing =path+'results/Benchmark_public/Benchmark_public_dataset_year_prediction'\n",
    "cv_list =  ['cv_1']\n",
    "list_name = ['RF_dUQ','PNN_MCDP','PNN_DE','EDL']\n",
    "list_ctx_constraint=None\n",
    "list_metrics = [Generic_metric(rmse,'Rmse_all', mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(average_coverage,\"Cov_all\", mask=None,list_ctx_constraint=None,reduce=True),\n",
    "                Generic_metric(sharpness,\"Aw_A\", mask=None,list_ctx_constraint=None,reduce=True,type_var='aleatoric'),\n",
    "                Generic_metric(sharpness,\"Aw_E\", mask=None,list_ctx_constraint=None,reduce=True,type_var='epistemic')]\n",
    "dict_perf = evaluate(storing, list_name, list_metrics,verbose=1,cv_list=cv_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
